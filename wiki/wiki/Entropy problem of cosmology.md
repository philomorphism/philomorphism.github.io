there's this problem of cosmology where we try to assign [[entropy]] to the "endpoints" of the universe in a particular model.

roger penrose on Closer to truth explains [here](https://closertotruth.com/video/penro-016/?referrer=8411). 

there's another [[Roger Penrose]]'s [lecture](https://www.youtube.com/watch?v=B-EpHQ7yl9c) in which he explains beautifully this problem and a solution is [[Conformal Cyclic Cosmology]](?). (NEED TO REVISE THE FOLLOWING STUFF)

### cosmic endpoints
some themes I have heard (most likely wrong and ambiguous):
1. entropy increases, time is passing by, so low at first and high at end.
2. low volume/something at first and high now or later, so high entropy at first and low at end.
3. energy distribution is in equilibrium modulo the fluctuations both at the beginning and at the end. so no entropy change.

### veritasium's video
[youtube](https://www.youtube.com/watch?v=DxL2HoqLbyA&t=78s). 
- perhaps wait for the answer to why the early universe is low entropy
- why is almost all the entropy in the [[neutrino]]s and [[CMB]]? ![[Pasted image 20230704001756.png]]
- the [[milky way galaxy]] with its centered [[black hole]] ![[Pasted image 20230704003754.png]]
- and finally including all of the black holes: ![[Pasted image 20230704003935.png]]
- WOAAAH!!! almost all of the entropy is in the black holes! all the information! and also that the universe has way more information that it did, i mean yeah it's obvious, but just too much of the information really! and that too in kinda one kind of objects only!
- there was a thing about [[population]] that i read/watched somewhere, it was a graph, showing the linear-then-exponential-then-converging-constant graph. how related is this with [[heat death]], [[semantics]]ally?

### sabine's video
[youtube](https://www.youtube.com/watch?v=89Mq6gmPo0s&t=1s)

sabine explains the 3rd one, that at the beginning the matter density was uniform high and this means the g-force is strong, and because g-froce is attractive it wants to draw the stuff in. but this is unlikely state and that at the end the matter density will be uniform and low. so the entropy is high. so it makes sense that 3=1.

also, sabine suggests to not talk about "order" at all, because it's not well-defined/formalized to compare it with entropy, which is defined by the number of microstate per a macrostate. because entropy is avg over microstates, it's kinda "throwing away" the information, so there're stuff we don't know if we just know the macrostate. which means high entropy = low informaiton, and low entropy = high informaiton. (checkout that twitter course on this by baez)

sabine thinks heat death is not the life will end. she really thinks new being (which will have their own definition, different from ours, of what a macrostate is) will (if possible) always be created. she says, **entropy is not fundamental** because we choose the scale from which we measure and make sense of it. macrostate is a frame of reference. she says, the 2nd law says the never decreases not that it increases (which i agree), and that this (always) increase of entropy thing comes into play because "we" lack the information of a system. she gives an example of particles in the box but i don't get it. she says there're are always macrostates that turn high entropy system into low one. (checkout susskind's lectures on boltzmann and entropy and demon and stuff). she says qm has nothing new to say. a microstate is all there exists and its entorpy is always zero both in cm and qm.

### refs
some relevant stuff:
- https://arxiv.org/abs/1505.05863
- https://arxiv.org/abs/1708.03677
- https://www.youtube.com/watch?v=YbovrTAr_js
